{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"aH5BXlk3zDOD"},"source":["# Introduction\n","Language Identification (LID) systems from voice are classification models that predict the spoken language from a given audio recording. The LID systems can facilitate the process of any speech processing system such as speech recognition (ASR) or speech translation systems. In speech-based assistant systems, LID works as a first step by selecting the appropriate grammar from a list of available languages for further semantic analysis. Also, these models can be employed in call centers in order to redirect an international user to an operator who is fluent in that identified language.\n","\n","## Objective\n","\n","The objective of this project is to use machine learning methods for constructing a LID model which can discriminate 4 languages; English, French, Arabic, Japanese. There are 2 expected phases.\n","The first phase is constructing a classifier. It is expected to compare the performance of different models, optimize the hyperparameters, and practice of finding the best model.\n","The second phase is the evaluation of the model in a simulated situation of real life deployment. The objective is to understand the challenge of generalization. It's also expected to analyze the result of the model’s performance and make hypothesis about the weak and strong aspect of models. The competition among models' accuracy can provide a better understanding of performance\n","\n","\n","## Data\n","\n","The provided dataset has been collected from TEDx talks YouTube for the Language Identification task from audio. The samples are recorded audio of speaker speech from available TEDx talks videos.\n","In order to have a standard sample's type, they follow below convention.\n","The length of recorded audio files should be around 5 seconds (5.00 - 5.99 seconds).\n","The format of audio files should be *.wav.\n","The sample rate of recording files should be 16 kHz (in mono format).\n","### Dataset\n","A repository contains recording files in the standard format (*.wav, 16kHz, mono, 5-6 seconds) and a *.txt file with 4 information (separated by , ) for each recorded file (one file per line) has been provided.\n","The 1st column is the name of *.wav file\n","The 2nd column is the URL address of YouTube video\n","The 3rd column is the starting time of recording from YouTube video\n","The 4th column is the label (language) of recorded speech (EN, FR, AR, JP)\n","### Evaluation set\n","A repository contains recording files in the standard format (*.wav, 16kHz, mono, 5-6 seconds) and a *.txt file with 2 columns as the file names and a the predicted label by your classification model."]},{"cell_type":"markdown","metadata":{"id":"O9H2EqQmzDOF"},"source":["### 1. As a first step, download the provided dataset and save in an accessible directory to your code."]},{"cell_type":"markdown","metadata":{"id":"ZzS9fDBGzDOF"},"source":["# Feature extractor\n","\n","By using [librosa](https://librosa.org/doc/latest/index.html) (more information [here](http://conference.scipy.org/proceedings/scipy2015/pdfs/brian_mcfee.pdf)) different time domain and frequency domain features can be extracted.\n","The librosa is a python package for audio and music analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcCnCA0jzDOG","outputId":"cd3854ce-97db-448b-a41d-67e3ba364046"},"outputs":[{"name":"stdout","output_type":"stream","text":["The duration of FR_001.wav in seconds: 5.494\n"]}],"source":["import librosa\n","\n","# sr should be set to your recording sample rate (16k)\n","# x,freq = librosa.load(\"[your_wav_files_directory]/FR_01.wav\",sr=16000)\n","x,freq = librosa.load(r\"H:\\Home\\Documents\\ProjetIA\\Dataset\\Dataset\\0000.wav\",sr=16000)\n","# The load function will return a time series value (x) and\n","#   the input sample rate (freq) which is 16000\n","print(\"The duration of FR_001.wav in seconds:\",len(x)/freq)"]},{"cell_type":"markdown","metadata":{"id":"bdhPNNo8zDOJ"},"source":["It would be proposed to use Mel-Frequency Cepstral Coefficients (MFCC) which is a short term spectral feature.\n","\n","They are commonly used to extract important information from a voice signal.\n","\n","MFCC can be extracted by *librosa.feature.mfcc()* as follows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQcAFFFVzDOJ","outputId":"7f126ab3-7d2b-4746-e127-1038314772bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["(40, 172)\n"]}],"source":["# This function will return n_mfcc number of MFCC per\n","#     a window of time in audio time series\n","x_mfcc=librosa.feature.mfcc(y=x,sr=freq, n_mfcc=40)\n","print(x_mfcc.shape)\n","# x_mfcc is an array with 40 values for a window of time\n","# The len(x_mfcc) is a proportion of wav file duration (5-6 seconds)"]},{"cell_type":"markdown","metadata":{"id":"B8ctP_JIzDOK"},"source":["The extracted MFCC features (x_mfcc in previous cell) has is a matrix with size of n_mfcc (here is 40 which can be changed) * a proportion of the imput duration\n","\n","### For example\n","\n","if your input audio file has a fix length of 5.00 seconds the calculated x_mfcc by above code would be a size of 40 * 157 \n","\n","if your input audio file has a fix length of 6.00 seconds the calculated x_mfcc by above code would be a size of 40 * 188 "]},{"cell_type":"markdown","metadata":{"id":"ritZaiaDzDOK"},"source":["You can find more information about MFCC feature and other types of feature such as Root Mean Squared Energy, Spectral Centroid, Zero Crossing Rate, etc. in  [this link](https://www.kaggle.com/volkandl/audio-processing-features-cnn-training) that can be used in this case. It is also possible to extract several types of features and concatenate them.  \n","\n","The length of extracted x_mfcc is a proportion of wav file duration. So it means the by having audio files with different duration (5.00 - 5.99 seconds) the length of extracted array would be varied.\n","In the case of LID problem, several methods for feeding features to model can be suggested."]},{"cell_type":"markdown","metadata":{"id":"F28I5nO2zDOL"},"source":["## Computing statistics from time series: \n","\n","By computing mean, variance, median, etc. it is possible to summarize and convert a list of values with variable length to one (or certain number of) value. In this method, the information related to the time will be lost. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKl12ktozDOM"},"outputs":[],"source":["def feature_extractor_1(audio_file_dir):\n","\n","    #load the audio files\n","    x,freq = librosa.load(audio_file_dir,sr=16000)\n","    #extract 20 MFCCs\n","    mfcc=librosa.feature.mfcc(y=x,sr=freq,n_mfcc=20)\n","    #calculate the mean and variance of each MFFC \n","    mean_mfccs=np.mean(mfcc,axis=1)\n","    var_mfccs=np.var(mfcc,axis=1)\n","    #return mean and variance as the audio file feature \n","    return list(mean_mfccs)+list(var_mfccs)"]},{"cell_type":"markdown","metadata":{"id":"aztsCxuezDOM"},"source":["## Converting sample to a fixed length:\n","\n","The audio time series data can be cut to a fix length (such as minimum length of 5.00 seconds) which called \\textit{Sequence Truncation}. Another method to have a fix length sequence is padding to a maximum length (for example 6.00 seconds) by concatenating a constant value such as 0 to the end (or beginning) of the sequence. These two model will keep the information related to the time in the time series data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuGpVP4xzDON"},"outputs":[],"source":["def feature_extractor_2(audio_file_dir):\n","\n","    #load the audio files\n","    x,freq = librosa.load(audio_file_dir,sr=16000)\n","    # trim the first 5 seconds (Sequence Truncation)\n","    length_of_5seconds=5*16000\n","    x_5sec=x[:length_of_5seconds]\n","    # extract 20 MFCCs\n","    mfccs_5sec=librosa.feature.mfcc(y=x_5sec,sr=freq,n_mfcc=20)\n","    # return mfcc of the first 5 sec as the audio file feature\n","    return mfccs_5sec"]},{"cell_type":"markdown","metadata":{"id":"OPlmwGh8zDON"},"source":["### 2. Read/Load your data\n","\n","Below code help you to read your data from your directory [your_TP_data] and extract feature based on [your_feature_extractor]\n","\n","At the end your data will be available in x_data (features) and y_data (labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vRnWtZRuzDOO"},"outputs":[],"source":["import csv\n","import numpy as np\n","#set data_dir to the directory of your data files\n","data_dir= \"H:\\Home\\Documents\\ProjetIA\\Dataset\\Dataset/\"\n","\n","# Read file info file to get the list of audio files and their labels\n","file_list=[]\n","label_list=[]\n","with open(data_dir+\"info.txt\", 'r') as file:\n","    reader = csv.reader(file)\n","    for row in reader:\n","        # The first column contains the file name\n","        file_list.append(row[0])\n","        # The last column contains the lable (language)\n","        label_list.append(row[-1]) \n","        \n","        \n","# create a dictionary for labels\n","lang_dic={'EN':0,'FR':1,'AR':2,'JP':3}\n","\n","# create a list of extracted feature (MFCC) for files\n","x_data=[]\n","\n","for audio_file in file_list:\n","    file_feature = feature_extractor_1(data_dir+audio_file)\n","    #add extracted feature to dataset \n","    x_data.append(file_feature)\n","\n","# create a list of labels for files\n","y_data=[]\n","for lang_label in label_list:\n","    #convert the label to a value in {0,1,2,3} as the class label\n","    y_data.append(lang_dic[lang_label])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PFgMO_u-zDOO"},"outputs":[],"source":["#random forest prend une matrice de taille inférieure ou égale a 2, donc je peux pas utiliser extractor_2 car \n","#il a une dimension de taille 3"]},{"cell_type":"markdown","metadata":{"id":"qqeSPFJ4zDOO"},"source":["### 3. Shuffle your data\n","\n","Using below code your data (features and corresponding labels) will be shuffled"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNgu7R6rzDOO"},"outputs":[],"source":["import random\n","\n","# shuffle two lists\n","temp_list = list(zip(x_data, y_data))\n","random.shuffle(temp_list)\n","x_data, y_data = zip(*temp_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nL3MUmiOzDOP"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(x_data,\n","                                                    y_data, \n","                                                    test_size=0.20,\n","                                                    shuffle=True)\n","\n","# Train model\n","#clf.fit(X_train, y_train)\n","\n","# Predict the test data\n","#y_pred = clf.predict(X_test)"]},{"cell_type":"markdown","metadata":{"id":"f8-Vxm2XzDOP"},"source":["### 4. Build your classifier\n","\n","Now everything (almost) ready to build your classifier.\n","\n","Below code is an example for creating an Random Forest classifier, training , and calculating its accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rvo1z1otzDOP","outputId":"f93fffaf-d935-4721-bfbf-4864c62444d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy::: 0.6779661016949152\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","\n","clf = RandomForestClassifier(max_depth=10)\n","#en mettant max_depth a 9 on obtient 90%\n","#clf.fit(x_data, y_data)\n","# Train model\n","clf.fit(X_train, y_train)\n","# Predict the test data\n","y_pred = clf.predict(X_test)\n","# the resulted accuracy is on a small set which is same for train and test\n","#print(\"Accuracy\",clf.score(x_data, y_data))\n","print(\"Accuracy:::\",accuracy_score(y_test,y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Zd61-QszDOP","outputId":"e4556091-dd2a-4eb1-f526-8240bbc32cce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy::: 0.4830508474576271\n"]}],"source":["\n","from sklearn.naive_bayes import GaussianNB\n","clf = GaussianNB()\n","#clf.fit(x_data, y_data)\n","# Train model\n","clf.fit(X_train, y_train)\n","# Predict the test data\n","y_pred = clf.predict(X_test)\n","# the resulted accuracy is on a small set which is same for train and test\n","#print(\"Accuracy\",clf.score(x_data, y_data))\n","print(\"Accuracy:::\",accuracy_score(y_test,y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3A9XWxfqzDOQ","outputId":"3530ab00-db68-43be-dee5-3ccfb51eea89"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy::: 0.711864406779661\n"]}],"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n","#clf.fit(x_data, y_data)\n","# Train model\n","clf.fit(X_train, y_train)\n","# Predict the test data\n","y_pred = clf.predict(X_test)\n","#print(\"Accuracy\",clf.score(x_data, y_data))\n","print(\"Accuracy:::\",accuracy_score(y_test,y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMDbQcmwzDOQ","outputId":"75e22971-d0de-427a-fc79-8a246164915e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy::: 0.4491525423728814\n"]}],"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","#clf = MLPClassifier(random_state=1, max_iter=300).fit(x_data, y_data)\n","clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n","#clf = GaussianNB()\n","#clf.fit(x_data, y_data)\n","# Train model\n","clf.fit(X_train, y_train)\n","# Predict the test data\n","y_pred = clf.predict(X_test)\n","\n","print(\"Accuracy:::\",accuracy_score(y_test,y_pred))\n","#print(\"score\" clf.score(X_train,y_train))\n","# the resulted accuracy is on a small set which is same for train and test\n","#il faut diviser la base de donnée et utiliser 80% des data_test pour tester\n","#utiliser y_pred = clf.predict(X_test) pour prédire l'accuracy au lieu de clf.score)\n","#useAccuracy(y_test,y_pred)\n","#print(\"Accuracy\",clf.score(x_data, y_data))\n"]},{"cell_type":"markdown","metadata":{"id":"UiVYionozDOR"},"source":["### 5. Have you used different data for train and test?"]},{"cell_type":"markdown","metadata":{"id":"4UI6bPd7zDOR"},"source":["### 6. Find a model with the best accuracy\n","\n","In order to find the model with highest accuracy the performance of below combiniations should be tested.\n","\n","1. Compare two feature extractors\n","2. Find the best hyperparameter for models : for example you can google \"sklearn RandomForestClassifier\" and go to [this link](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to find the RandomForestClassifier hyperparameteres (some of RandomForestClassifier's hyperparametere : n_estimators , criterion , max_depth )\n","3. Compare different classification algorithems\n","\n","\n","Below you can find a lits of algorithem with hyperparameters that can be tested:\n","\n","[Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) \n","\n","[C-Support Vector Classification](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) kernel: {'linear', 'sigmoid', 'rbf'}\n","\n","[Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) n_estimators: {10, 100, 1000} , criterion: {'gini', 'entropy'} , max_features: {'auto', 'sqrt', 'log2'} , bootstrap : {True, False}\n","\n","[Multi-layer Perceptron classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) activation: {'tanh', 'relu'} , solver: {'sgd', 'adam'} , hidden_layer_sizes: {(100,10,),(1000,100,)}"]},{"cell_type":"markdown","metadata":{"id":"1JHdggUUzDOR"},"source":["#### Be careful 1: All arguments (inputs) of a algorithem are not hyperparameter to optimize. Read their discription! For example it does not make anysense to optimize random_state or n_jobs."]},{"cell_type":"markdown","metadata":{"id":"eSfrCWjkzDOR"},"source":["#### Be careful 2 : In order to find the best value for a hyperparameter they shuold be compare when all of other variable are same. "]},{"cell_type":"markdown","metadata":{"id":"3zATHLsZzDOS"},"source":["#### Be careful 3: The performance (accuracy) of models can be compare only on test set not training set. It is suggested to follow k-fold cross validaton."]},{"cell_type":"markdown","metadata":{"id":"1OzrE4BUzDOS"},"source":["### 6+. Supplementary hints\n","\n","1. The impact of PCA on result\n","2. Use an ensemmble model (aggregate (majority votes) the result of several algorithms)"]},{"cell_type":"markdown","metadata":{"id":"Cfa7r5wMzDOS"},"source":["### 7. Impact of dataset size\n","\n","For your best model campare the impact of dataset size on the accuracy. While you have used all of provided dataset so far, train and test your model with 50% and 25% of provided dataset. "]},{"cell_type":"markdown","metadata":{"id":"EHu0yKAtzDOS"},"source":["### 8. Predict label of Evaluation set\n","\n","Below code can help you to predict a label for each file in evaluation set and save the result on a file called [YourName_YourModelName_Version].csv\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpnw4cXHzDOT"},"outputs":[],"source":["#set data_dir to the directory of your data files\n","data_dir= \"H:\\Home\\Documents\\ProjetIA\\Dataset\\Dataset/\"\n","\n","# Read file info file to get the list of audio files and their labels\n","file_list=[]\n","label_list=[]\n","with open(data_dir+\"1Info.txt\", 'r') as file:\n","    reader = csv.reader(file)\n","    for row in reader:\n","        # The first column contains the file name\n","        file_list.append(row[0])\n","\n","lang_dic={'EN':0,'FR':1,'AR':2,'JP':3}\n","class2lang_dic={0:\"EN\",1:\"FR\",2:\"AR\",3:\"JP\"}\n","\n","for test_sample in file_list:\n","    test_sample_feature=feature_extractor(data_dir+test_sample)\n","    predicted=class2lang_dic[clf.predict([test_sample_feature])[0]]\n","    print(f'Predicted class: \"{predicted}\"')\n","    # save the predicted output in Output_evaluation.txt\n","    with open(data_dir+\"[SanogoKassoum_SVC_Version].csv\",'a+') as file:\n","        file.write(f\"{test_sample},{predicted}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"m00EnMwJzDOT"},"source":["# Congratulation You are ready to submit your result"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}